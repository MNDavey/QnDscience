---
title: "felipe_gfs_rspatial_prac"
author: "Leslie Roberson"
date: "4/2/2020"
output: html_document
---

## Day one, 2 April 2020

First R session

1. Make and format maps
2. density maps
3. extract data from a raster
4. Combine and make calculations from multiple rasters                                                                                     
## Assumptions
we know what a CRS is, a projection is, how to prepare your files before an analysis
*reprojecting data is better in GIS than in R

So here he already prepared all the layers

```{r setup, include=FALSE}

```

## types of data

vector: c() means vector. a group of different elements
dataframe: can have different columns of different types of elements
list: collection of multiple objects that you can call independently 
  (e.g multiple dataframes in a list, or a list of shapefiles, or list of rasters)

## split function

use this for large data, so you can apply a funciton to smaller bits of data

```{split}

data_sp <- split(data, data$spp_id) # will make a list, with one element for each of your spp_id

## convert shapefile to dataframe
map.df <- fortify(shapefile) # like making a sf objecti but simpler, just making a df from your shapefile

list[1] # calls the first element of your list

## or can only apply a funciton to certain elements of your list (eg certain species)
allplots <- lapply(data_sp[1:3], create_maps, map.df. onlypoints = TRUE) # create_maps is Felipe's function

```

## piles of map

```{stack}

# stack to import a raster stack, which is layers of rasters (so layers of different values or variables grouped together into a raster)
# different to a list of rasters - you'd use lapply for that. That's a collection of raster elements
```

## Day 2, 9 April 2020

# Intro to Loops

```{loops}

paste()
# when you want to concatenate numbers and letters into a sentence 
print(paste("we have session at", 9))
print(paste("we have session at", 10))
print(paste("we have session at", 11))
print(paste("we have session at", 12))
# this is annoying to copy and paste the different sessions with different numbers

## a loop is more efficient
# make a sequence of numbers
9:15
# now, concatenate each number in the sequence to the sentence and print it
for(hour in 9:15){
  print(paste("we have session at", hour))
}
# if you remove print, nothing happens
for(hour in 9:15){
  paste("we have session at", hour)
}
# so oyu need to store your result somewhere - first you have to create an empty object to store your results

# so here we create a list to store outputs (remember, a list is a list of objects, can be various types of objects)
list_of_sentences <- list()
for(hour in 9:15){
  list_of_sentences <- paste("we have session at", hour)
} # this overwrites each time and only stores the last sentence (with hour 15)

# so tell it to record all the results for each hour using the index []
list_of_sentences <- list()
for(hour in 9:15){
  list_of_sentences[[hour]] <- paste("we have session at", hour)
} # resturns the position of the sentence within the list in [[]]
list_of_sentences 

list_of_sentences <- list(1,2,3,4) # create list with 4 elements
# so you're telling it to store the results of your loop in those 4 positions

# NULL elements still get stored in teh list (so hours 1-8) get stored as HNULL, and you end up with 15 objects in your list

# so you can add things to your list at whatever position you want

## often see this as i

list_of_sentences <- list()
for(i in 1:15){ # for i in 1:15, 
  list_of_sentences[[i]] <- paste("we have session at", i) # do this loop and store it here
} 
list_of_sentences 

Reduce(list_of_sentences) # one way to remove any elements in the list that don't have anthing in them

```

## Day 4

random notes

sapply - makes a vector
lapply - makes a list. Can do the same thing as a loop
apply - for a dataframe 

When working with a big dataframe in R, the best thing you can do is split it


## Day 5

More on loops

datacamp.com >> good tool for R and lots of other things

```{day 5 loops}

mydf <- data.frame(x = runif(100), y = rnorm()) # create vector of 100 random numbers with a normal distribution 

# create a 3rd column contianing the sum of hte first 2 cols, by row
for (i in 1:nrow(mydf)) { # all the rows in the df 
  # length(mydf) is number of columns, or if you have list.files for a list of rasters, then length is what you need
  mydf[i,3] <- mydf[i,1] + mydf[i,2]
}

## create a df, take the mean of hte 1st and 2nd cols but only for the last 50 row, and store the result in a vector

mydf  <- data.frame(x = runif(200), min = 50, max = 500)

myvector <- vector()
for (i in (nrow(mydf)-50):nrow(mydf)){
  myvector[i] <- mean(mydf[i,1] + mydf[i,2]) 
}
## Can do the same thing with apply. this function basically takes your dataframe and loops it. 
# so don't put apply in a loop bc it's a loop within a loop

apply(mydf, 1, sum) # apply to rows
apply(mydf, 2, sum) # apply to columns 

mydf$newcol <- apply(mydf, 1, sum) 
mydf$newcol <- apply(mydf[1:50,], 1, sum) # apply to first 50 rows

# EVERYTHING IN [] BEFORE COMMA IS ROWS, EVERYTHING AFTER IS COLUMNS

```


## Day 5? or 5?

```{day 6}

#<>><<> Loop exercise
# create a list of datarfames of dim 3 cols and 50 rows
# then apply a loop to extract the first and third columns with the last 20 rows

mydf1 <- data.frame(replicate(3,sample(0:100,50,rep=TRUE)))
## OR could do it this way:
#mydf1 <- data.frame(x = runif(50), y = rnorm(100), z = rnorm(100))
mydf2 <- data.frame(replicate(3,sample(101:1000,50,rep=TRUE)))
mydf3 <- data.frame(replicate(3,sample(1001:2000,50,rep=TRUE)))

mylistdfs <- list(mydf1, mydf2, mydf3)

colstokeep <- list()
for (i in 1:length(mylistdfs)){
  colstokeep[[i]] <- mylistdfs[[i]][(nrow(mylistdfs[[i]])-20):nrow(mylistdfs[[i]]),c(1,3)]
}


#<><><>>< raster and shapefile exercise 

myshape <- readOGR(dsn = ".", layer = "shape_layer")

myshape@data # see attribute table

library(NLMR)
raster1 <- NLMR::nlm_fbn(33, 33, fract_dim = 1) # this foo ggregates cells with similar values 
# 33, 33 are the dims

raster::plot(raster1, terrain.colors(3))

crs_myshape <- crs(myshape)
extent(raster1) <- extent(myshape) # this is the max and min coord values
## assign that extent to our raster
projection(raster1) <- CRS(as.character(crs_myshape))
plot(raster1)

## save raster to your working directory
writeRaster(raster1, "./YOURSUBFOLDER/raster1.tif")

## call multiple rasters

myrasters <- list.files("./", pattern = "*.tif", full.names = TRUE) # shows only the names as a vector
## call them with a loop into a list of rasters
listrasters <- list()
for (i in 1:length(myrasters)){
  listrasters[[i]] <- raster(myrasters[[i]])
}
# can also do this with lapply(myrasters)...


## <><><><> now extract the cells inside each of the following polygons

# first weire going to split our shapefile based on the unique identifier
Colombia@data$ID <- 1:nrow(Colombia@data) # add unique identifier as a column
# split shapefile based on that id column, which will make a list of shapefiles (each with one feature)
split(Colombia, Colombia@data$ID) # name of shapefile, name of column with unique identifier
# can also do this based on any col - can be categorical (would get a list of shapefiles for each category, each with a some features)

## crop and make a raster

target_raster <- raster1
# crop that raster to extent of the polygon efature (in this case the feature called "depart)
raster.polygon <- crop(target_raster, extent(depart), snap = "near")
# crop to polygon edge and include the borders, and convert to raster
raster.polygon <- rasterize(depart, raster.polygon, mask = TRUE)
crs(raster.polygon) <- crs(depart)
# extract cells
cells <- rasterToPoints(raster.polygon)
cells <- as.data.frame(cells) # all the cells from that polygon
## add an id col to the df to keep track
cells$departmentCol <- depart$NAME_1

```

